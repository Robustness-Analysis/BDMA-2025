---
title: "Clustering Analisys through HClust and KMeans"
output:
  html_document: default
  pdf_document: default
date: "2024-06-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

# Preliminary steps

### Load necessary libraries and files

#### Load libraries

```{r, include=FALSE}
# Packages that need to be loaded
pacman::p_load(caret, citation, data.table, dplyr, earth, farff, ggpubr, ggplot2, iml, knitr, rpart, tidyverse , tidyr, xtable, factoextra, proxy, dominanceanalysis, clustertend, MASS, smacof, vegan, cluster, flexclust)

```

#### Load files

```{r, include=FALSE}
# Load files
datasets <- c("analcatdata_authorship", "badges2", "banknote", "blood-transfusion-service-center", "breast-w", "cardiotocography", "climate-model-simulation-crashes", "cmc", "credit-g", "diabetes", "eucalyptus", "iris", "kc1", "liver-disorders", "mfeat-karhunen", "mfeat-zernike", "ozone-level-8hr", "pc4", "phoneme", "qsar-biodeg", "tic-tac-toe", "vowel", "waveform-5000", "wdbc", "wilt")

```

------------------------------------------------------------------------

# Select datasets

### Auxiliary functions to obtain information about the datasets

Create a function to get the number of instances from a dataset

```{r, include=FALSE}
# Function to get the number of instances from a dataset
get_num_instances <- function(dataset) {
  num_instances <- nrow(dataset)
  return(num_instances)
}

```

Create a function to determine the type of each attribute

```{r, include=FALSE}
# Function to determine the type of each attribute
get_attribute_type <- function(dataset) {
  # Exclude the "class" column
  dataset_subset <- dataset[, !names(dataset) %in% "class"]
  
  # Initialize counts
  numerical_count <- 0
  nominal_count <- 0
  
  # Loop through columns
  for (col in names(dataset_subset)) {
    if (is.numeric(dataset_subset[[col]])) {
      numerical_count <- numerical_count + 1
    } else {
      nominal_count <- nominal_count + 1
    }
  }
  
  # Return counts
  return(list(numerical = numerical_count, nominal = nominal_count))
}

```

Create a function to determine if dataset is binary or multiclass

```{r, include=FALSE}
# Function to determine if dataset is binary or multiclass
is_binary <- function(dataset) {
  unique_classes <- unique(dataset$class)
  num_unique_classes <- length(unique_classes)
  
  if (num_unique_classes == 2) {
    return("binary")
  } else if (num_unique_classes > 2) {
    return("multiclass")
  } else {
    stop("Invalid number of unique classes")
  }
}

```

### Information about the datasets

Create a table that shows all datasets and a summary of their data: **`characteristics_df`**

```{r include=FALSE}
# Create a dataframe to store the summary
  characteristics_df <- data.frame(
  dataset_name = character(0),
  instances_n = numeric(0),
  attributes_num = numeric(0),
  attributes_nom = numeric(0),
  dataset_type = character(0),
  stringsAsFactors = FALSE
)

# Iterate through datasets
for (dataset_name in datasets) {
  # Load dataset
  filename = paste0("datasets/", dataset_name, ".rds")
  dataset <- readRDS(filename)
  # Calculate summary metrics
  num_instances <- get_num_instances(dataset)
  attribute_types <- get_attribute_type(dataset)
  dataset_type <- is_binary(dataset)
  # Add to summary dataframe
    characteristics_df <- bind_rows(characteristics_df, data.frame(
    dataset_name = dataset_name,
    instances_n = num_instances,
    attributes_num = attribute_types$numerical,
    attributes_nom = attribute_types$nominal,
    dataset_type = dataset_type
  ))
}
  
characteristics_df$dataset_type = ifelse(characteristics_df$dataset_type == "binary", 0, 1)

# Convert all data to numeric
characteristics_df$instances_n <- as.numeric(characteristics_df$instances_n)
characteristics_df$attributes_num <- as.numeric(characteristics_df$attributes_num)
characteristics_df$attributes_nom <- as.numeric(characteristics_df$attributes_nom)
characteristics_df$dataset_type <- as.numeric(characteristics_df$dataset_type)

# Combine attribute columns
#characteristics_df$attributes <- characteristics_df$attributes_num + characteristics_df$attributes_nom

# Print the summary dataframe
print(characteristics_df)

saveRDS(characteristics_df, "files/clustering/characteristics.rds")

```

### Select datasets of different sizes to use as a test set

Save the test datasets' names in **`test_data`**

```{r}
# Combination of datasets for testing (leave-one-out testing)
test_data <- c("analcatdata_authorship", "breast-w", "cardiotocography","liver-disorders")

saveRDS(test_data, "files/clustering/test_data.rds")

```

# Clustering

## Clustering on the original data

#### Scale the data

In **`clusters_scaled`** we have the scaled data of the characteristics

```{r include=FALSE}
# Euclidean distances between the rows
clusters_scaled <- scale(characteristics_df[,-1])

# Add dataset names back
clusters_scaled <- cbind(dataset_name = characteristics_df$dataset_name, clusters_scaled)

# Turn into dataframe
clusters_scaled <- as.data.frame(clusters_scaled)

# Print the scaled dataframe
print(clusters_scaled)

saveRDS(clusters_scaled, "files/clustering/cl_scaled.rds")

```

#### Obtain euclidean distances matrix

Make sure all necessary data is numeric

```{r include=FALSE}
clusters_scaled$instances_n <- as.numeric(clusters_scaled$instances_n)
clusters_scaled$attributes_num <- as.numeric(clusters_scaled$attributes_num)
clusters_scaled$attributes_nom <- as.numeric(clusters_scaled$attributes_nom)
clusters_scaled$dataset_type <- as.numeric(clusters_scaled$dataset_type)

saveRDS(clusters_scaled, "files/clustering/cl_scaled.rds")

```

In **`d`** we have the distance matrix for the scaled data

```{r include=FALSE}
set.seed(1)
# Euclidean distances between the rows
dmatrix <- dist(clusters_scaled[,-1])

# Print the distance matrix
print(dmatrix)

saveRDS(dmatrix, "files/clustering/dmatrix.rds")

```

### Create new dataframes without test set

Save in **`train_set`** the dataframes without the test datasets in a list of dataframes, obtained from **`clusters_scaled`**

```{r include=FALSE}
# Create new dataframe without the test set
train_set <- clusters_scaled[!clusters_scaled$dataset_name %in% test_data, ]

# Create new dataframe with only the test set
test_set <- clusters_scaled[clusters_scaled$dataset_name %in% test_data, ]

saveRDS(train_set, "files/clustering/train_set.rds")
saveRDS(test_set, "files/clustering/test_set.rds")

```

#### Distance matrices for new dataframe

Obtain the new distance matrices for the **`train_set`**

```{r include=FALSE}
# Obtain distances for the training set
train_dmatrix <- dist(train_set[,-1])

# Print the distance matrix
print(train_dmatrix)

saveRDS(train_dmatrix, "files/clustering/train_dmatrix.rds")

```

### Calculate elbow and silhouette to find optimal number of clusters

#### Elbow for **`train_set`**

```{r echo=FALSE}
# "silhouette", "wss", "gap_stat"
print(fviz_nbclust(train_set[,-1], kmeans, method = "wss") + geom_vline(xintercept = 5, linetype = 2) + labs(subtitle = "Elbow method") + theme_minimal())

```

#### Get a dataframe with the dataset's names and row ID's

Stored in **`group_list`**

```{r include=FALSE}
# Create a new table with dataset names and rownames
groups_df <- cbind(ID = rownames(train_set), dataset_name = train_set$dataset_name)

# Turn into dataframe
groups_df <- as.data.frame(groups_df)

# Make sure all necessary data is numeric
groups_df$ID <- as.numeric(groups_df$ID)

```

#### Silhouette for [K = 4]{.underline} with each dataframe in **`train_set`**

```{r echo=FALSE}
# Perform hierarchical clustering
hclusters <- hclust(train_dmatrix, method = "ward.D")

# Plot dendrogram
plot(hclusters, labels = rownames(train_set), main = "Heirarchal Grouping", xlab = "Observations", sub = NULL, ylim=c(0,1))

# Divide dendogram into groups
groups <- cutree(hclusters, k = 4)
rect.hclust(hclusters, k = 4, border = "red")

# Add dendogram groups to the train set data
groups_df$hclust_4 <- groups

# Compute silhouette coefficient for hierarchical clustering
sil <- silhouette(groups, train_dmatrix, hclusters$labels)

# Create silhouette plot
plot(sil, main = "HClust Silhouette with K = 4")

```

#### Silhouette for [K = 5]{.underline} with each dataframe in **`train_set`**

```{r echo=FALSE}
# Perform hierarchical clustering
hclusters <- hclust(train_dmatrix, method = "ward.D")

# Plot dendrogram
plot(hclusters, labels = rownames(train_set), main = "Heirarchal Grouping", xlab = "Observations", sub = NULL, ylim=c(0,1))

# Divide dendogram into groups
groups <- cutree(hclusters, k = 5)
rect.hclust(hclusters, k = 5, border = "red")

# Add dendogram groups to the train set data
groups_df$hclust_5 <- groups

# Compute silhouette coefficient for hierarchical clustering
sil <- silhouette(groups, train_dmatrix, hclusters$labels)

# Create silhouette plot
plot(sil, main = "HClust Silhouette with K = 5")

```

#### Silhouette for K = 6 with each dataframe in **`train_set`**

```{r echo=FALSE}
# Perform hierarchical clustering
hclusters <- hclust(train_dmatrix, method = "ward.D")

# Plot dendrogram
plot(hclusters, labels = rownames(train_set), main = "Heirarchal Grouping", xlab = "Observations", sub = NULL, ylim=c(0,1))

# Divide dendogram into groups
groups <- cutree(hclusters, k = 6)
rect.hclust(hclusters, k = 6, border = "red")

# Add dendogram groups to the train set data
groups_df$hclust_6 <- groups

# Compute silhouette coefficient for hierarchical clustering
sil <- silhouette(groups, train_dmatrix, hclusters$labels)

# Create silhouette plot
plot(sil, main = "HClust Silhouette with K = 6")

```

> K = 5 seems to be optimal in this case

### K-Means with the original characteristics

#### K = 4 K-Means with each dataframe in **`train_set`**

```{r echo=FALSE}
# K = 4
set.seed(1)

# Run kmeans clustering
kmeans_4 <- kmeans(train_set[,-1], centers = 4, nstart = 25)

# Extract the centroids
centroids_4 <- kmeans_4$centers

# Convert result of kmeans to kkca from flexclust
kcca_4 <- as.kcca(kmeans_4, train_set[,-1])

# Add cluster labels to the groups dataframe
groups_df$kmeans_4 <- kmeans_4$cluster

# Visualize the clusters
plot(fviz_cluster(kmeans_4, data = train_set[,-1], 
             geom = "point", ellipse.type = "convex", 
             ggtheme = theme_minimal()) + coord_fixed(ratio = 1))

# Compute silhouette coefficient for hierarchical clustering
sil_k4 <- silhouette(kmeans_4$cluster, train_dmatrix, train_set$dataset_name)

# Create silhouette plot
plot(sil_k4, main = "K = 4 Silhouette")
```

#### K = 5 K-Means with each dataframe in **`train_set`**

```{r echo=FALSE}
# K = 5
set.seed(1)

# Run kmeans clustering
kmeans <- kmeans(train_set[,-1], centers = 5, nstart = 25)

# Extract the centroids
centroids_5 <- kmeans$centers

# Convert result of kmeans to kkca from flexclust
kcca_5 <- as.kcca(kmeans, train_set[,-1])

# Add cluster labels to the groups dataframe
groups_df$kmeans_5 <- kmeans$cluster

# Visualize the clusters
plot(fviz_cluster(kmeans, data = train_set[,-1], 
             geom = "point", ellipse.type = "convex", 
             ggtheme = theme_minimal()) + coord_fixed(ratio = 1))

# Compute silhouette coefficient for hierarchical clustering
sil_kmeans_5 <- silhouette(kmeans$cluster, train_dmatrix, train_set$dataset_name)

# Create silhouette plot
plot(sil_kmeans_5, main = "K = 5 Silhouette")

```

#### K = 6 K-Means with each dataframe in **`train_set`**

```{r echo=FALSE}
# K = 6
set.seed(1)

# Run kmeans clustering
kmeans <- kmeans(train_set[,-1], centers = 6, nstart = 25)

# Extract the centroids
centroids_6 <- kmeans$centers

# Convert result of kmeans to kkca from flexclust
kcca_6 <- as.kcca(kmeans, train_set[,-1])

# Add cluster labels to the groups dataframe
groups_df$kmeans_6 <- kmeans$cluster

# Visualize the clusters
plot(fviz_cluster(kmeans, data = train_set[,-1], 
             geom = "point", ellipse.type = "convex", 
             ggtheme = theme_minimal()) + coord_fixed(ratio = 1))

# Compute silhouette coefficient for hierarchical clustering
sil_kmeans_6 <- silhouette(kmeans$cluster, train_dmatrix, train_set$dataset_name)

# Create silhouette plot
plot(sil_kmeans_6, main = "K = 6 Silhouette")

```

##### Store the Centroids and the K-Centroids Cluster Analysis

```{r include=FALSE}
# Save the kmeans for k = 4
saveRDS(kmeans_4, file = "files/clustering/kmeans.rds")

# Save the centroids
saveRDS(centroids_4, file = "files/clustering/centroids.rds")

# Save the KCCA
saveRDS(kcca_4, file = "files/clustering/kcca.rds")

```

### Multi-dimensional scaling plot (MDS) with the original characteristics

#### MDS Shepard plot for each dataframe in **`train_set`**

```{r echo=FALSE}
# Compute Shepard for the original distance matrix
fit_mds <- mds(dmatrix)
plot(fit_mds, plot.type = "Shepard")

# Compute Shepard for train_set
fit_mds <- mds(train_dmatrix)
plot(fit_mds, plot.type = "Shepard")

```

#### MDS Kruskal's Non-metric Multidimensional Scaling for each dataframe in **`train_set`**

```{r echo=FALSE}
# Nonmetric MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name
fit <- isoMDS(dmatrix, k=2) # k is the number of dim

# Plot solution without labels
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Kruskal's Non-metric MDS", type="n")
points(x, y)

# Compute Kruskal's MDS for train_set
# Nonmetric MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name
fit <- isoMDS(train_dmatrix, k=2) # k is the number of dim

# Plot solution without labels
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Kruskal's Non-metric MDS", type="n")
points(x, y)

```

#### Show as table of coordinates

```{r echo=FALSE}
# Create a table with the results
coord_df <- data.frame(
  ID = train_set$dataset_name,
  Coordinate1 = x,
  Coordinate2 = y
)

names(coord_df)[names(coord_df) == 'ID'] <- 'dataset_name'
names(coord_df)[names(coord_df) == 'Coordinate1'] <- 'coordinate_1'
names(coord_df)[names(coord_df) == 'Coordinate2'] <- 'coordinate_2'

# Print the results table
print(coord_df)

```

## Plot original data with coordinates clusters

```{r include=FALSE}
# Merge the dataframes
groups_df <- left_join(groups_df, coord_df, by = "dataset_name")

```

### MDS for K = 4 clusters

```{r echo=FALSE}
# Plot solution
x <- groups_df$coordinate_1
y <- groups_df$coordinate_2

# K = 4
# Create the plot
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
     main="Kruskal's Non-metric MDS", type="n")

# Define colors for each cluster
colors <- c("darkred", "darkgreen", "darkorange", "lightblue") 
point_colors <- colors[groups_df$kmeans_4]

# Add points colored by cluster
points(x, y, col=point_colors, pch=16)

# Add text labels
#text(x, y, labels=plot_df[,1], cex=0.7, col=point_colors)
```

### MDS for K = 5 clusters

```{r echo=FALSE}
# Plot solution
x <- groups_df$coordinate_1
y <- groups_df$coordinate_2

# K = 5
# Create the plot
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
     main="Kruskal's Non-metric MDS", type="n")

# Define colors for each cluster
colors <- c("darkred", "darkgreen", "darkorange", "lightblue", "violet") 
point_colors <- colors[groups_df$kmeans_5]

# Add points colored by cluster
points(x, y, col=point_colors, pch=16)

# Add text labels
#text(x, y, labels=plot_df[,1], cex=0.7, col=point_colors)

```

### MDS for K = 6 clusters

```{r echo=FALSE}
# Plot solution
x <- groups_df$coordinate_1
y <- groups_df$coordinate_2

# K = 5
# Create the plot
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
     main="Kruskal's Non-metric MDS", type="n")

# Define colors for each cluster
colors <- c("darkred", "darkgreen", "darkorange", "yellow", "lightblue", "violet") 
point_colors <- colors[groups_df$kmeans_5]

# Add points colored by cluster
points(x, y, col=point_colors, pch=16)

# Add text labels
#text(x, y, labels=plot_df[,1], cex=0.7, col=point_colors)

```

#### Store the plots

```{r include=FALSE}
# Save the groups
saveRDS(groups_df, "files/clustering/groups.rds")

```
