# Load results
results_df <- readRDS("files/results.rds")
plots <- readRDS("files/clustering/plots.rds")
groups_df <- readRDS("files/clustering/groups.rds")
# Predict cluster assignment for new dataset
kcca_assignment <- predict(kcca, newdata = test_set[,-1])
# Print the cluster assignment
print(kcca_assignment)
for(i in 1:nrow(test_set)) {
# Calculate Euclidean distance between the new vector and each centroid
distances <- apply(centroids, 1, function(centroid) sqrt(sum((i - centroid)^2)))
# Determine the nearest centroid
cluster_assignment <- which.min(distances)
# Print the cluster assignment
print(cluster_assignment)
if(i != nrow(test_set)) {print("----------------")}
}
# Loop through techniques
for(t in techniques) {
plot_name <- paste0(t, "_10")
if (plot_name %in% names(plots)) {
res <- as.data.frame(plots[[plot_name]]$data)
# Filter the data for cluster 4
res_cluster2 <- subset(res, cluster == 2)
# Calculate 1 - mean_kappa
res_cluster2$kappa_loss <- 1 - res_cluster2$mean_kappa
# Filter where 1 - kappa is less than or equal to 0.05
filtered_res <- subset(res_cluster2, kappa_loss <= 0.05)
# Get the highest value in the percentage column
if (nrow(filtered_res) > 0) {
highest_value <- max(filtered_res$percentage)
cat("Technique:", t, "- Highest percentage where Kappa loss is 5% for cluster 2 is:", highest_value, "\n")
} else {
cat("Technique:", t, "- No entries where Kappa loss is 5% for cluster 2.\n")
}
} else {
cat("Plot", plot_name, "not found in the list.\n")
}
}
data <- subset(results_df, dataset_name == "analcatdata_authorship" & noise == 30)
# Calculate 1 - mean_kappa
data$kappa_loss <- 1 - data$kappa
# Loop through techniques
for(t in techniques) {
filtered_data <- subset(data, kappa_loss <= 0.15)
# Get the highest value in the percentage column
if (nrow(filtered_data) > 0) {
highest_value <- max(filtered_data$percentage)
cat("Technique:", t, "- Highest percentage where Kappa loss is 5% for breast-w is:", highest_value, "\n")
} else {
cat("Technique:", t, "- No entries where Kappa loss is 5% for breast-w .\n")
}
}
# Identify elements ending with "rf_10"
elements_to_plot <- grep("rda_10$", names(plots), value = TRUE)
# Plot the data for each of these elements using base R
for (element in elements_to_plot) {
plot_data <- plots[[element]]
plot(
plot_data,
type = "l",
main = paste("Plot of", element),
xlab = "Index",
ylab = "Value"
)
}
# Identify elements ending with "rf_10"
elements_to_plot <- grep("rda_20$", names(plots), value = TRUE)
# Plot the data for each of these elements using base R
for (element in elements_to_plot) {
plot_data <- plots[[element]]
plot(
plot_data,
type = "l",
main = paste("Plot of", element),
xlab = "Index",
ylab = "Value"
)
}
# Identify elements ending with "rf_10"
elements_to_plot <- grep("rda_30$", names(plots), value = TRUE)
# Plot the data for each of these elements using base R
for (element in elements_to_plot) {
plot_data <- plots[[element]]
plot(
plot_data,
type = "l",
main = paste("Plot of", element),
xlab = "Index",
ylab = "Value"
)
}
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
pacman::p_load(caret, citation, data.table, dplyr, earth, farff, ggpubr, ggplot2, iml, knitr, rpart, tidyverse , tidyr, xtable)
library(GGally) # extensión de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
# Load files
datasets <- readRDS("files/datasets.rds")
method_names = readRDS("files/method_names.rds")
noise_level <- readRDS("files/noise.rds")
noise_names <- readRDS("files/noise_names.rds")
instances_names = readRDS("files/instances_names.rds")
quartiles_names = c("0", "25", "50", "75", "100")
#characteristics_df = readRDS("files/clustering/characteristics.rds")
# Load results
results_df <- readRDS("results/results_plot_d.rds")
results_df <- results_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
quartiles_df <- readRDS("results/results_plot_q.rds")
quartiles_df <- quartiles_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
meanKLC <- readRDS("results/meanKLC.rds")
meanKLC_q <- readRDS("results/meanKLC_q.rds")
# Transform the data
wide_data <- meanKLC_q %>%
unite("noise_percentage", noise, percentage, sep = "_") %>%
spread(key = noise_percentage, value = kappa_loss)
# View the transformed data
print(wide_data)
distance_matrix <- dist(wide_data, method = "euclidean")
k_list = c(3, 4, 5)
for(i in k_list) {
# Perform hierarchical clustering
hclusters <- hclust(distance_matrix, method = "ward")
# Plot dendrogram with labels
plot(hclusters, hang = -1, labels = wide_data$technique, main = "Hierarchical Grouping", xlab = "Observations", sub = NULL)
rect.hclust(hclusters, k = i, border = "red")
# Plot dendrogram without labels
plot(hclusters, hang = -1, main = "Hierarchical Grouping", xlab = "Observations", sub = NULL)
rect.hclust(hclusters, k = i, border = "red")
# Divide dendrogram into groups
groups <- cutree(hclusters, k = i)
# Compute silhouette coefficient for hierarchical clustering
sil <- silhouette(groups, dist = distance_matrix)
# Create silhouette plot
plot(sil)
}
install.packages("RWeka")
library(RWeka)
# Packages that need to be loaded
pacman::p_load(caret, iml, xtable, ggpubr, citation, dplyr, earth, lime)
version
setwd("~/github/BDMA-2025/markdown")
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(ggplot2)
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
quartiles_names = c("25", "50", "75", "100")
# Load results
#deciles_df <- readRDS("../results/KLC_plot_deciles.rds")
deciles_df <- readRDS("../results/KLC_plot_deciles_popular.rds")
#deciles_df <- deciles_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
#saveRDS(deciles_df, file = "../results/KLC_plot_deciles.rds")
#saveRDS(deciles_df, file = "../results/KLC_plot_deciles_popular.rds")
#quartiles_df <- readRDS("../results/KLC_plot_quartiles.png")
#quartiles_df <- readRDS("../results/KLC_plot_quartiles_popular.png")
#quartiles_df <- quartiles_df %>% select(-accuracy, -kappa, -dataset_order, -method_order)
#saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles.rds")
#saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles_popular.png")
df1 <- deciles_df %>%
group_by(technique, noise) %>%
summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
ungroup()
df2 <- deciles_df %>%
group_by(technique, noise, percentage) %>%
summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
ungroup()
#df2_q <- quartiles_df %>%
#    group_by(technique, noise, percentage) %>%
#    summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2)) %>%
#    ungroup()
#saveRDS(df2, file = "../results/meanKLC_d.rds")
#saveRDS(df2_q, file = "../results/meanKLC_q.rds")
saveRDS(df2, file = "../results/meanKLC_d_popular.rds")
#saveRDS(df2_q, file = "../results/meanKLC_q_popular.rds")
for(instance in quartiles_names) {
# Filter data for the current instance percentage
filtered_data <- subset(df2, percentage == instance & noise != 5)
# Create plot
p2 <- ggplot(filtered_data, aes(x = noise, y = kappa_loss, color = factor(technique))) +
geom_point() +
geom_line(aes(noise)) +
labs(x = "Noise", y = "Kappa Loss", color = "Technique") +
ggtitle(paste0("Kappa Loss Curves by technique, noise and ", instance, " % of instances altered")) +
theme_bw() +
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1))
# Print plot
print(p2)
}
#ggsave("../results/plots/KLC_techniques_q.png", p2, width = 40, height = 40, dpi = 600)
ggsave("../results/plots/KLC_techniques_d_popular.png", p2, width = 40, height = 40, dpi = 600)
# Create plot
p2 <- ggplot(df2, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(percentage)) +
labs(x = "Noise", y = "Kappa Loss") +
ggtitle("Kappa Loss Curves by technique, noise and percentage of instances altered") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1)) +
facet_wrap(~ technique)
# Print plot
print(p2)
#ggsave("../results/plots/KLC_means_deciles.png", p2, width = 40, height = 40, dpi = 600)
ggsave("../results/plots/KLC_means_deciles_popular.png", p2, width = 40, height = 40, dpi = 600)
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally) # extensión de ggplot2
library(factoextra) # visualizacion de los clusters
library(NbClust) # determinar el mejor numero de grupos
library(cluster) # medidas de evaluacion como silhouette
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
#quartiles_names = c("25", "50", "75", "100")
# Load results
#meanKLC <- readRDS("../results/meanKLC_d.rds") # This is df2 from Aggregate_Curves
#meanKLC_q <- readRDS("../results/meanKLC_q.rds") # This is df2_q from Aggregate_Curves
meanKLC <- readRDS("../results/meanKLC_d_popular.rds") # This is df2 from Aggregate_Curves
#meanKLC_q <- readRDS("../results/meanKLC_q_popular.rds") # This is df2_q from Aggregate_Curves
# Transform the data
wide_data <- meanKLC %>%
unite("noise_percentage", noise, percentage, sep = "_") %>%
spread(key = noise_percentage, value = kappa_loss)
# View the transformed data
print(wide_data)
distance_matrix <- dist(wide_data, method = "euclidean")
# Define consistent color palette for clusters
cluster_colors <- c(
"1" = "#4FB28F",  # Green
"2" = "#8F4FB2",  # Purple
"3" = "#3681F7",  # Blue
"4" = "#F65215"   # Orange
)
# Perform hierarchical clustering
hclusters <- hclust(distance_matrix, method = "ward.D")
# Cut the tree to get k=4 clusters
k <- 4
clusters <- cutree(hclusters, k = k)
# Print cluster assignments
print(clusters)
# First get unique techniques in the same order as used for clustering
techniques <- wide_data$technique
# Create the mapping dataframe
technique_clusters <- data.frame(
technique = techniques,
cluster = clusters
)
# Create a named vector to map colors to specific clusters
# This ensures consistent color usage across all plots
cluster_colors <- c(
"1" = "#4FB28F",  # Green
"2" = "#8F4FB2",  # Purple
"3" = "#3681F7",  # Blue
"4" = "#F65215"   # Orange
)
# Save the dendrogram with colored rectangles by cluster
png("../results/plots/dendogram.png", width = 4000, height = 3000, res = 600)
plot(hclusters, hang = -1, labels = wide_data$technique,
main = paste("Hierarchical Grouping (k =", k, ")"),
xlab = "Observations", sub = NULL)
# Create colored rectangles with consistent colors per cluster
rect.hclust(hclusters, k = k, border = cluster_colors[as.character(1:k)])
invisible(dev.off())
# Generate silhouette plot with consistent colors
png("../results/plots/silhouette_t.png", width = 4000, height = 3000, res = 600)
sil <- silhouette(clusters, dist = distance_matrix)
# Use the same colors for silhouette plot as for dendrogram
plot(sil, col = cluster_colors[as.character(sort(unique(clusters)))],
main = paste("Silhouette Plot (k =", k, ")"))
invisible(dev.off())
# Join cluster assignments with original data
meanKLC_with_clusters <- meanKLC %>%
left_join(technique_clusters, by = "technique")
# Calculate mean kappa loss for each cluster, noise level, and percentage
cluster_means <- meanKLC_with_clusters %>%
group_by(cluster, noise, percentage) %>%
summarize(kappa_loss = round(mean(kappa_loss, na.rm = TRUE), 2), .groups = 'drop')
print(cluster_means)
# Create plots for individual techniques (optional)
for(instance in instances_names) {
# Filter data for the current instance percentage
filtered_data <- subset(meanKLC_with_clusters, percentage == instance)
# Create plot with consistent colors
p1 <- ggplot(filtered_data, aes(x = noise, y = kappa_loss, color = factor(cluster))) +
geom_point() +
geom_line(aes(group = technique)) +
# Use consistent colors based on cluster assignment
scale_color_manual(values = cluster_colors) +
labs(x = "Noise", y = "Kappa Loss", color = "Cluster") +
ggtitle(paste0("Kappa Loss Curves by technique, noise and ", instance, " % of instances altered")) +
theme_bw() +
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1))
# Print plot
print(p1)
}
# Create plots for cluster means
for(instance in instances_names) {
# Filter data for the current instance percentage
filtered_data <- subset(cluster_means, percentage == instance)
# Create plot with consistent colors
p2 <- ggplot(filtered_data, aes(x = noise, y = kappa_loss, color = factor(cluster))) +
geom_point() +
geom_line(aes(group = cluster)) +
# Use consistent colors based on cluster assignment
scale_color_manual(values = cluster_colors) +
labs(x = "Noise", y = "Kappa Loss", color = "Cluster") +
ggtitle(paste0("Kappa Loss Curves by cluster, noise and ", instance, " % of instances altered")) +
theme_bw() +
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1))
# Print plot
print(p2)
}
# Create an empty list to store plots
plot_list <- list()
# Create all plots and store them in the list
for(i in seq_along(instances_names)) {
instance <- instances_names[i]
# Filter data for both techniques and clusters
filtered_tech_data <- subset(meanKLC_with_clusters, percentage == instance)
filtered_cluster_data <- subset(cluster_means, percentage == instance)
# Create combined plot with consistent colors
combined_plot <- ggplot() +
# Add technique lines with colors based on their cluster
geom_line(data = filtered_tech_data,
aes(x = noise, y = kappa_loss, group = technique, color = factor(cluster)),
linetype = "solid", alpha = 0.5) +
geom_point(data = filtered_tech_data,
aes(x = noise, y = kappa_loss, group = technique, color = factor(cluster)),
alpha = 0.5) +
# Add thicker cluster lines to show the averages
geom_line(data = filtered_cluster_data,
aes(x = noise, y = kappa_loss, group = cluster, color = factor(cluster)),
linewidth = 1.5) +
geom_point(data = filtered_cluster_data,
aes(x = noise, y = kappa_loss, group = cluster, color = factor(cluster)),
size = 3) +
# Set the specific color mapping - consistent with other plots
scale_color_manual(name = "Cluster", values = cluster_colors) +
# Customize the plot
scale_y_continuous(limits = c(0.0, 0.5), breaks = seq(0, 1, by = 0.1)) +
labs(x = "Noise",
y = "Kappa Loss",
title = paste0(instance, "% of instances altered")) +
theme_bw() +
theme(legend.position = "right")
# Store plot in list
plot_list[[i]] <- combined_plot
}
# Arrange all plots in a grid using patchwork
if (requireNamespace("patchwork", quietly = TRUE)) {
# Using patchwork
library(patchwork)
combined_grid <- wrap_plots(plot_list, ncol = 1) +
plot_annotation(title = "Kappa Loss Curves by Technique and Cluster")
print(combined_grid)
# Save the grid plot
png(filename = "../results/plots/cluster_curves_grid.png",
width = 4000, height = 12000, res = 600)
print(combined_grid)
dev.off()
} else {
# Print plots individually if patchwork is not available
for (p in plot_list) {
print(p)
}
}
knitr::opts_chunk$set(echo = TRUE)
# Packages that need to be loaded
library(dplyr)
library(ggplot2)
# Load files
datasets <- readRDS("../files/datasets.rds")
method_names = readRDS("../files/method_names.rds")
# Remove svmLinear for testing on most popular key attribute
method_names <- method_names[! method_names %in% c("svmLinear")]
noise_level <- readRDS("../files/noise.rds")
noise_names <- readRDS("../files/noise_names.rds")
instances_names = readRDS("../files/instances_names.rds")
quartiles_names = c("0", "25", "50", "75", "100")
# Load results
mia_df <- readRDS("../results/most_important_attr/mia_df.rds")
noiseMIA_list <- readRDS("../results/noise/noise_list.rds")
#instancesCM_list = readRDS("../results/instances/instancesCM_list.rds")
#confusion_list <- readRDS("../results/conf_matrices/confusion_matrices.rds")
instancesCM_list = readRDS("../results/instances/instancesCM_list_popular.rds")
confusion_list <- readRDS("../results/conf_matrices/confusion_matrices_popular.rds")
# Function to get the number of instances from a dataset
get_num_instances <- function(dataset) {
num_instances <- nrow(dataset)
return(num_instances)
}
# Function to determine the type of each attribute
get_attribute_type <- function(dataset) {
# Exclude the "class" column
dataset_subset <- dataset[, !names(dataset) %in% "class"]
# Initialize counts
numerical_count <- 0
nominal_count <- 0
# Loop through columns
for (col in names(dataset_subset)) {
if (is.numeric(dataset_subset[[col]])) {
numerical_count <- numerical_count + 1
} else {
nominal_count <- nominal_count + 1
}
}
# Return counts
return(list(Numerical = numerical_count, Nominal = nominal_count))
}
# Function to determine if dataset is binary or multiclass
is_binary <- function(dataset) {
unique_classes <- unique(dataset$class)
num_unique_classes <- length(unique_classes)
if (num_unique_classes == 2) {
return("Binary")
} else if (num_unique_classes > 2) {
return("Multiclass")
} else {
stop("Invalid number of unique classes")
}
}
# Turn list into dataframe
deciles_df = data.frame(matrix(ncol = 6, nrow = 0))
colnames(deciles_df) = c("dataset_name", "technique", "noise", "percentage", "accuracy", "kappa")
for(dataset in datasets) {
for(method in method_names) {
for(noise in noise_names) {
for(instance in instances_names){
# Get the values for accuracy and kappa
a <- confusion_list[[dataset]][[1]][[method]][[noise]][[instance]]$accuracy
k <- confusion_list[[dataset]][[1]][[method]][[noise]][[instance]]$kappa
# Add row to results dataframe
deciles_df[nrow(deciles_df) + 1,] = c(dataset, method, noise, instance, a, k)
}
}
}
}
deciles_df$accuracy <- as.numeric(deciles_df$accuracy)
deciles_df$kappa <- as.numeric(deciles_df$kappa)
#quartiles_df$accuracy <- as.numeric(quartiles_df$accuracy)
#quartiles_df$kappa <- as.numeric(quartiles_df$kappa)
# Round the values of accuracy and kappa to two decimals
deciles_df$accuracy <- round(deciles_df$accuracy, digits = 2)
deciles_df$kappa <- round(deciles_df$kappa, digits = 2)
#quartiles_df$accuracy <- round(quartiles_df$accuracy, digits = 2)
#quartiles_df$kappa <- round(quartiles_df$kappa, digits = 2)
deciles_df$percentage <- as.numeric(deciles_df$percentage)
deciles_df <- deciles_df %>% mutate(noise = recode(noise, "noise_0" = "0", "noise_5" = "5", "noise_10" = "10", "noise_20" = "20", "noise_30" = "30", "noise_40" = "40", "noise_50" = "50", "noise_60" = "60", "noise_70" = "70", "noise_80" = "80", "noise_90" = "90", "noise_100" = "100"))
deciles_df$noise <- as.numeric(deciles_df$noise)
#saveRDS(deciles_df, file = "../results/results_deciles.rds")
saveRDS(deciles_df, file = "../results/results_deciles_popular.rds")
#saveRDS(quartiles_df, file = "../results/results_quartiles.rds")
#saveRDS(quartiles_df, file = "../results/results_quartiles_popular.rds")
# Get Kappa loss in order to print Kappa Loss Curves
# Calculate 1 - mean_kappa rounded to two decimals
deciles_df$kappa_loss <- round(1 - deciles_df$kappa, 3)
# Create a new column to control the order of datasets
deciles_df$dataset_order <- factor(deciles_df$dataset_name, levels = datasets)
# Create a new column to control the order of methods
deciles_df$method_order <- factor(deciles_df$technique, levels = method_names)
# Create plot
p <- ggplot(deciles_df, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(x = "Instances", y = "Kappa", color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1)) +
facet_grid(method_order ~ dataset_order, scales = "free")
# Print plot
print(p)
#ggsave("../results/plots/KLC_plot_deciles.png", p, width = 40, height = 40, dpi = 600)
ggsave("../results/plots/KLC_plot_deciles_popular.png", p, width = 40, height = 40, dpi = 600)
#saveRDS(deciles_df, file = "../results/KLC_plot_deciles.rds")
saveRDS(deciles_df, file = "../results/KLC_plot_deciles_popular.rds")
# Get Kappa loss in order to print Kappa Loss Curves
# Calculate 1 - mean_kappa rounded to two decimals
quartiles_df$kappa_loss <- round(1 - quartiles_df$kappa, 3)
# Create a new column to control the order of datasets
quartiles_df$dataset_order <- factor(quartiles_df$dataset_name, levels = datasets)
# Create a new column to control the order of methods
quartiles_df$method_order <- factor(quartiles_df$technique, levels = method_names)
# Create plot
p <- ggplot(quartiles_df, aes(x = percentage, y = kappa_loss, color = factor(noise))) +
geom_point() +
geom_line(aes(group = factor(noise))) +
labs(x = "Instances", y = "Kappa", color = "Noise") +
theme_bw() +
scale_y_continuous(limits = c(0.0, 1), breaks = seq(0, 1, by = 0.1)) +
facet_grid(method_order ~ dataset_order, scales = "free")
# Print plot
print(p)
#ggsave("../results/plots/KLC_plot_quartiles.png", p, width = 40, height = 40, dpi = 600)
ggsave("../results/plots/KLC_plot_quartiles_popular.png", p, width = 40, height = 40, dpi = 600)
#saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles.rds")
saveRDS(quartiles_df, file = "../results/KLC_plot_quartiles_popular.rds")
